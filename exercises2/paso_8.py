# ============================================================
# PASO 8 â€” Haz que escriba cÃ³digo
# ============================================================
#
# â”€â”€ Â¿QuÃ© aprendimos en la sesiÃ³n 1? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# El LLM entiende las preguntas perfectamente, pero no puede
# calcular sobre 16.334 filas. Cuando le pides "Â¿cuÃ¡l es la
# tasa de churn del plan bÃ¡sico?", se inventa un nÃºmero.
#
# â”€â”€ La idea clave de la sesiÃ³n 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# Â¿Y si en vez de pedirle LA RESPUESTA, le pedimos que
# escriba EL CÃ“DIGO para calcularla?
#
#   Antes (sesiÃ³n 1):
#     Usuario: "Â¿CuÃ¡l es la tasa de churn?"
#     LLM:     "La tasa de churn es del 12.3%" â† inventado
#
#   Ahora (sesiÃ³n 2):
#     Usuario: "Â¿CuÃ¡l es la tasa de churn?"
#     LLM:     "churned = df[df['status']=='churned']
#               tasa = len(churned)/len(df)*100"  â† cÃ³digo real
#     Python:  ejecuta el cÃ³digo â†’ 2.52%  â† resultado real
#
# Esto se llama "text-to-code": el LLM traduce lenguaje
# natural a cÃ³digo Python. Python calcula. El nÃºmero es real.
#
# â”€â”€ El cambio estÃ¡ en el prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# En paso_6, el prompt del sistema decÃ­a:
#   "Eres un analista de datos. Responde a las preguntas..."
#
# Ahora le vamos a decir:
#   "Genera SOLO cÃ³digo Python que responda a la pregunta.
#    No expliques nada. Solo el cÃ³digo."
#
# Eso es todo. El mismo LLM, la misma API, pero con una
# instrucciÃ³n diferente.
#
# â”€â”€ Tu reto â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# Completa la lÃ­nea marcada con ___ en el prompt del sistema.
# Necesitas decirle al LLM que genere cÃ³digo Python, no texto.
#
# Cuando funcione, prueba preguntas como:
#   "Â¿CuÃ¡ntos registros tiene el dataset?"
#   "Â¿CuÃ¡ntos socios de cada plan hay?"
#   "Â¿CuÃ¡l es la tasa de churn del plan bÃ¡sico?"
#
# VerÃ¡s que el LLM responde con CÃ“DIGO en vez de con texto.
# En el siguiente paso aprenderemos a ejecutar ese cÃ³digo.
#
# â”€â”€ Si has terminado antes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
#   A. Prueba la misma pregunta que en paso_6:
#        "Â¿CuÃ¡l es la tasa de churn del plan bÃ¡sico?"
#      Â¿El cÃ³digo que genera tiene sentido? Â¿Lo entiendes?
#
#   B. Prueba una pregunta mÃ¡s compleja:
#        "Â¿CuÃ¡l es el margen medio por plan?"
#      Â¿Genera cÃ³digo correcto? Â¿Usa las columnas correctas?
#
#   C. Prueba en inglÃ©s vs espaÃ±ol. Â¿Genera mejor cÃ³digo
#      con preguntas en un idioma u otro?
#
#   D. Pregunta algo que NO se puede responder con los datos:
#        "Â¿CuÃ¡l es la satisfacciÃ³n media de los socios?"
#      Â¿QuÃ© hace? Â¿Genera cÃ³digo que falla? Â¿Inventa una
#      columna que no existe?
#
# Ejecuta:  streamlit run exercises2/paso_8.py
# ============================================================

import streamlit as st
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI()

st.title("FitLife â€” Text-to-Code")
st.caption("Paso 8 â€” El LLM genera cÃ³digo en vez de responder")

df_members = pd.read_csv("data/fitlife_members.csv")
df_context = pd.read_csv("data/fitlife_context.csv")

st.subheader("Datos cargados")
st.write(f"Socios: **{len(df_members)}** registros | Contexto: **{len(df_context)}** meses")

st.divider()

prompt = st.chat_input("Pregunta sobre los datos de FitLife...")

if prompt:
    with st.chat_message("user"):
        st.write(prompt)

    with st.chat_message("assistant"):

        # â”€â”€ PROMPT DEL SISTEMA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # La instrucciÃ³n clave estÃ¡ en la primera lÃ­nea.
        # Completa el ___ para que el LLM genere cÃ³digo Python
        # en vez de responder con texto.
        #
        # Pista: necesitas decirle algo como
        #   "Genera solo cÃ³digo Python que responda..."
        #   o "Escribe Ãºnicamente cÃ³digo Python..."

        system_prompt = f"""___

Tienes acceso a dos DataFrames ya cargados:

1. df_members â€” datos de socios ({len(df_members)} filas)
   Columnas: {list(df_members.columns)}

2. df_context â€” contexto mensual ({len(df_context)} filas)
   Columnas: {list(df_context.columns)}

Reglas:
- Usa pandas para las operaciones.
- El cÃ³digo debe terminar con: resultado = <lo que calcules>
- NO uses print(). Solo asigna el resultado final a la variable "resultado".
- NO incluyas import ni read_csv â€” los datos ya estÃ¡n cargados.
- Devuelve SOLO el bloque de cÃ³digo, sin explicaciones antes ni despuÃ©s.
- Envuelve el cÃ³digo en triple backtick python."""

        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ]
        )

        generated = response.choices[0].message.content
        st.write("**CÃ³digo generado por el LLM:**")
        st.code(generated, language="python")
        st.write("ğŸ‘† De momento solo lo muestra. En el paso 9 lo ejecutaremos.")
